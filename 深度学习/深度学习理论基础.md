- 数据集  
  - 模型会总结归纳数据集中场景和目标状态的各种类别，如果数据集不包含某一个目标状态或场景，在模型分类时，可能对该种类型鲁棒性较差  
- 训练集，验证集  
  - 交叉验证法    
    - 将训练集拆分为N个等分，分N次，每次将其中一等分作为验证集，剩余部分作为训练集，训练模型后，用验证集进行验证  
    - 通过选取不同的等分作为验证集，最后求取平均准确率作为标准，选取超参数hyperparameter设置  
    - 数据量少的时候可以尝试采用交叉验证法  
    - 通常有相应的验证集，不需要使用交叉验证法  
- 测试集  
  - 用于度量模型的泛化能力，即模型应用在新数据上的效果  
- 损失函数LOSS  
  - 定量地度量模型在数据集上表现的有多差的函数  
  - 损失函数可以统计均值，和，以及平方和，线性变换不会改变LOSS/W的梯度，所以求和的均值或求和效果是一样的  
    但是求平方和却会得到不同的结果，求平方再求和，相当于对LOSS进行了非线性变换    
  - 至于在使用中，使用哪一种方式，可将其视为超参数，指数是1或2  
  - 关于损失函数值域，最小值以及最大值  
  - 损失函数的设计方法
    - 促使让正确分类结果比其他结果得分更高  
  - 损失函数如果在训练过程中，存在问题，可能有很多很多的原因，需要积累经验  
- 正则化  
  - 通过损失来控制模型参数复杂度的技术  
  - 一方面模型在学习过程中，想变得复杂来适应数据  
  - 另一方面，正则化则想让模型呈现出一种特殊的方式，不至于太复杂（稀疏性）  
  - 正则化可能会造成训练结果变坏，但是却让模型更具有泛化能力  
  - L2正则化的效果，可以看成是尽可能地去平展参数，参数数值都比较平均，意味着，L2正则化想要尽可能地考虑  
    更多的特征，尽可能地利用这些维度（正则特性）  
- 初始化
  - 一般初始化时参数的值都比较小，需考虑在训练初次时的影响，可以此来对模型进行正确性验证  
    观察模型输出得到的loss是否与理论的loss接近或差别很大  
  - 小的随机数 例如，标准差为0.01的高斯随机数，对深度网络效果很差，浅层网络效果适用    
  - 应该怎么样的初始化权重？  
- 优化器  
  - 梯度下降  
    - 计算梯度  
      - 并不是用集合所有数据来计算梯度，数据量大，效率太低，但是梯度下降方向准确，即使包含了噪点  
      - 用一个小的子集进行梯度估算，使用mini-batch虽然可以提高计算效率，但容受噪点影响  
        所以，loss在更新过程中是曲折下降的  
      - 考虑GPU的容量，找寻合适的mini-batch大小  
    - 学习率更新策略  
      - 一般在初始阶段，选取一个较高的学习率，之后再减小学习率，慢慢更新  
    - 更新步长  
      - 不仅仅关于学习率  
      - 考虑每一次更新，W变化的大小  
      - 包括学习率，梯度，动量的计算方式等  
      - 观察W直至最终停止更新的整个过程的变化路径  
- 反向传播  
  - 计算图  
- 神经网络  
  - 神经网络中间层，不同的神经元就是一个线性分类器，可以理解为不同状况的模板  
  - 如何分辨出你的神经网络不健康  
- 数据预处理  
  - 归一化
  - 零中心化
  - 其他
    - PCA，协方差矩阵，对角矩阵，白化处理，单位矩阵，这些都是数据预处理的方式  
      但PCA或Whitening白化处理不能应用在图像处理中，因为图像是高维数据，导致协方差巨大，无法处理      
- Batch Normalization  
  - 让每一层输入有一个很好的正太分布  
  - 神经网络可以学习是否让BN起作用  
  - 有一定的正则化效果，因为在计算mean和std时，BN考虑到了小批量的数据整体特征  
  - BN的参数gamma和sigma可以学习来延展BN的效果，不一定是标准正太分布  
  - 在训练和测试时,BN的计算有略微的不同  
  - 什么时候需要BN呢，待了解  
- Babystting the training neural networks  
  - 损失函数正确性检查    
    - 取消正则化，初始化参数为小值，验证损失函数正确性  
    - 启动正则化，再次验证损失函数  
  - 完整性检查  
    - 对于训练的小批量数据，让神经网络的能力略微地过拟合，让损失函数为0
      这表明，反向传播以及参数更新应该在正常工作，学习率应该设置地也合理    
    - 调大训练数据量，找寻合适的学习率，观察损失函数下降趋势，调整学习率      
    - 试想学习率极小比如1e-6或极大时1e6，训练会怎样  
    - 经验得，学习率限制在一个合适的小区间  
- 超参数优化  
  - 对数空间取值  
  - 网格搜索  
  - 随机取样搜索，这个方法更常用更优秀  
  - 学习率，正则化系数，dropout系数等  
- 可视化分析  
  - loss损失函数  
  - 准确率  
- 权重更新比率及权重大小  
  - 权重更新值/权重大小，这个比率在1e-3左右是比较好的  
- SGD  
  - 每次重新测算位置的速度，梯度相当于加速度，速度为系数\*梯度    
- Momentum Update  
  - 梯度相当于加速度，系数\*梯度得到速度，再考虑惯性即上一时刻的速度\*系数  
- Neterov Momentum Update  
  - 惯性+速度，惯性即上一时刻的速度，但是速度为惯性到达的点的速度，并不是此刻位置的速度，位置通过  
    x+uv(t-1)得到，速度为u\*derivate(x+uv(t-1)),最后的更新增量为，u1v(t-1)+u2derivate(x+uv(t-1))    
- AdaGrad update  
  -在参数更新时，引入梯度标准化,但是随训练进行，最后梯度大小为0，停止更新  
  ```python 
  cache += dx**2
  x += - learning_rate * dx / (np.sqrt(cache) + eps)
  ```
- RMSProp  
  在AdaGrad基础上改进了cache的更新方式
  ```python 
  cache = decay_rate * cache + (1 - decay_rate) * dx**2
  x += - learning_rate * dx / (np.sqrt(cache) + eps)
  ```
  让cache能够更新，并且不至于很大，也能满足梯度自适应更新时的补偿效果    
- Adam  
  - 结合了动量和自适应的作用  
  - 动量用于稳定梯度更新的方向，综合了前几个梯度的衰减和  
  - 自适应用于稳定每次更新时的步长，综合了前几个梯度的按元素操作的衰减和  
  - 关于超参数，beta1，beta2的设定  
  - 还有考虑出事阶段动量和自适应量为0时的补偿措施  
  ```python 
  # t is your iteration counter going from 1 to infinity
  m = beta1*m + (1-beta1)*dx
  mt = m / (1-beta1**t)
  v = beta2*v + (1-beta2)*(dx**2)
  vt = v / (1-beta2**t)
  x += - learning_rate * mt / (np.sqrt(vt) + eps)
  ```
  可以想象我们希望期初由于动量和自适应量本身是0所以可以在期初几次迭代中能够不那么小  
  在后面这两者的量大小大起来可以适应训练后，让他们不变化  
  所以这个补偿量随迭代次数是开始时很小，之后迅速变大到1的函数  
- 二阶优化
  - 即考虑损失函数曲率变化，实际应用中不是太多，所以先不做深入  
- 模型集成  
  - 经验表明，训练单一模型，在测试时将这些模型结果求均值，最后能得到约2%的性能提升  
  - 也可以在训练单一模型时，通过在训练过程中设置检查点，存储不同迭代次数下的模型，最后对这些检查点结果求均值，也可以起到模型集成的效果  
- 随机失活dropout  
  - 可防过拟合，是的，因为dropout后，网络的神经元按比率降低，模型容量变小
  - 随机失活更重要的意义在于强化神经元的特征提取能力  
    - 这样去理解，网络神经元提取特征是为了能准确分类目标，但是如果得知在分类时，随机地一些神经元被失活，为了完成分类任务，
      **对于目标的特征提取是冗余的，本来只需要耳朵眼睛鼻子嘴巴，现在有更多的特征比如眉毛脸框等等，需要这个冗余以达到即使我们之中有部分神经元失活,我们也能完成准确分类的任务,因为有随机失活，我们需要依赖更多的特征达到准确分类任务的目标，因为你不能完全依赖于某一个特征，因为每个特征都可能失活**  
    - 另一种解释，就是应用了dropout的模型相当于多个小模型的集成模型，小的模型规模等于整个模型与dropout比率的乘积  
      相当于每一次训练，只是在训练网络的一部分，由这一部分组成的独立网络，最终使用的是整个网络，所以是由多个独立网络的集成  
      但是这样的话，问题是，每个独立网络被训练的次数却很少，因为总的训练次数是有限的，比如迭代10epoch，每个epoch20个batch抽样，则总共200次训练  
      但是可能在训练中，考虑极端情况，比如每次都不一样，那么相当于每个独立网络只训练了一次，这样的话会不会产生训练不足的问题  
      这样的训练与不采用dropout技术，纯粹的单一模型训练，再在结果时求平均有什么区别
      1. 是训练不足，但是这个会产生多大影响  
      2. dropout随机产生网络，不用手工设计网络  
  - 需要注意在训练和测试时，dropout的设置是不一样的，为了弥补在训练时，神经元输出期望值缩减的问题，有两种方法进行弥补  
    1. 是在测试时，在每一层神经元激活函数后，乘以同样的失活系数，缩减输出  
    2. 是'逆向失活'，只在训练时，在激活函数的输出值后除以相应的失活系数，扩大输出期望，这样在测试时就不用改变输出了  
    3. 但是失活和反向失活确是有一些不同，因反向失活改变了每一层输出值的大小，由于非线性激活函数，按道理会改变之后输出的分布，又回到了前向和后向传播数据流和梯度流的问题  
- 梯度检验  
  - 自己看笔记学习  
- 卷积网络  
  - 最重要的一点就是对于卷积网络可视化的理解  
    1. 可视化后观察到，从底层到高层，提取的特征由基础变得复杂，基础特征和复杂特征之间是组合关系，基础组合成高级复杂  
    2. 卷积核探测特征不受特征位置的影响，比如说，横线，不管横线在图片上方还是下方都能检测，这与线性分类器不同，这个特点具有位置不变性  
    3. 卷积核的感受野问题，基础卷积核感受野小，探测的特征初级，恰巧需要小的感受野，比如横线，需要在任意小的像素块中探测，一是因为这样的基础特征在任意小的像素块中都能呈现，所以需要去探测任意小的像素块是否有这样的基础特征，二是卷积核任意的小探测的精度可能越高；但是高级卷积核，需要大的感受野，比如探测鼻子，需要至少在一定尺寸下的像素块中才能探测到鼻子，尺寸太小，像素块都容纳不下鼻子的图像，巧妙的是，逐层卷积运算，都满足了以上两点需求  
    4. 卷积核感受野的大小和探测的特征有关，也和需要探测的精度有关，特征越基础，所需感受野最小尺寸越小，像素块最小尺寸应满足能容纳探测特征；感受野越小，探测精度越高  
    5. 卷积核可视化后的图像，与线性分类器一样，呈现了哪些元素，就表明，这些元素对提取特征有贡献  
    6. 需要关注卷积核应用到每一层输入图像时探测特征的过程，类似线性分类器去扫描图像  
    7. 因为逐层卷积运算，会产生很多层的激活图，或特征图，对于特征图的理解，不能看图所呈现的图像来看，比如特征图是是一个有波纹的图像并不代表它就是一个波纹，特征图是相当于一个编码，数值越大表明对于特征提取器即卷积核的响应越大，表明此位置有卷积核所表征的特征；所以之后的卷积运算即对一层一层的编码进行组合来探测相应位置是否具有卷积核表征的特征，直到最后，特征图编码表达了高级抽象特征的表达程度及位置信息    
    8. 卷积核的图象可以理解为相应的特征，激活图或特征图的图象表现了特征的响应程度，是一种编码  
    9. 卷积核的另一个特点是共享权重和局部链接，每一个特征图的一个元素都是一个神经元，这些神经元共享同一套权重，且只关注输入图像的一部分；这样做的好处共享权重是控制了模型的能力，防止过拟合，另外也有了卷积核特征提取的位置不变性；而局部连接是探测基础特征的必要条件，如果关注整体图像会导致参数很多，局部连接足以满足提取特征的要求  
    10. 关于可视化，第一层卷积核可视化后，可以从图象看出代表的意义，正在探测什么样的特征，因为它们与图片直接相连，之后的卷积核可视化图象表明上一级特征的组合，不容易看出探测的是什么特征；而特征图的可视化图象表明位置信息和特征存在性，图象不一定是拟物的    
  - 其他诸如，卷积运算，输入的尺寸、深度等信息都是可以按照基本公式计算了  
  - 但是认识卷积核特殊的一点是关于卷积核的深度，在卷积运算时，输入图像的深度与卷积核深度一致，相应位置进行内积计算，输出一个数  
  - 比较特别的1\*1的卷积核，用于缩减数据深度，**如何理解1\*1的卷积运算？**  
  - 池化操作  
    - 最大值池化  
    - 平均值池化  
    - 都是为了压缩数据  
    - 丢失部分空间信息，以存在性来考察小像素块中是否有激活的特征  
- 卷积、全连接的不变性  
  - 这里面涉及了分类讨论的思想或者分情况看问题的思想，为了应对不同的情况，可以产生冗余的卷积，为了应对不同的情况，需要全连接层对各种情况有冗余能力全连接和前面提到的模板很类似，训练数据包含的各种情况越多，模板从经验角度产生冗余能力，全连接就会对不同业务场景有更强鲁棒性  
